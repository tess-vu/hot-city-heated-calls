{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f717022a",
   "metadata": {},
   "source": [
    "NYC 311 request filtering using the 5 targeted weather stations, making this project a regional heat exposure proxy, *not* a micro-climate model.\n",
    "Quality-ofLife (QoL) proxy variables are determined as follows:\n",
    "\n",
    "- **qol_calls:** Count of 311 calls in QoL-related categories.\n",
    "- **total_calls:** Count of all 311 calls in a week.\n",
    "- **qol_pct:** qol_calls / total_calls * 100.\n",
    "- **qol_rate_pc:** qol_calls / 1000 residents.\n",
    "\n",
    "Timing is June through August, which is considered summer time for US.\n",
    "Temporal resolution is by weeks.\n",
    "Spatial resolution is in block groups.\n",
    "Final resolution is 311 data aggregated to block groups × week and citywide weather data aggregated by week.\n",
    "\n",
    "NYC 311 category selection for QoL have to consider the below:\n",
    "- Meaningful livability impact reflecting disruptions or degradation of everyday life (rather than purely administrative or regulatory issues).\n",
    "- Likely to respond to heat/stress, things that might get worse under high heat or strain (e.g., noise, sanitation, infrastructure).\n",
    "- Sufficient volume and spatial distribution, common enough to show variation across block groups and days.\n",
    "- Clear linkage to place and time, must have incident location, timestamp, etc.\n",
    "\n",
    "**Heat and housing livability domain:**\n",
    "\n",
    "- HEAT/HOT WATER\n",
    "- UNSANITARY CONDITION\n",
    "- GENERAL CONSTRUCTION\n",
    "- PAINT/PLASTER\n",
    "- ELECTRIC\n",
    "- PLUMBING\n",
    "- MOLD\n",
    "- WATER LEAK\n",
    "- BUILDING CONDITION\n",
    "- UNSAFE BUILDING\n",
    "- ELEVATOR\n",
    "\n",
    "**Noise and outdoor comfort domain:**\n",
    "\n",
    "- NOISE - RESIDENTIAL\n",
    "- NOISE - STREET/SIDEWALK\n",
    "- NOISE - VEHICLE\n",
    "- NOISE - PARK\n",
    "\n",
    "**Sanitation and public space domain:**\n",
    "\n",
    "- SANITATION CONDITION\n",
    "- DIRTY CONDITIONS\n",
    "- LITTER BASKET / REQUEST\n",
    "- ILLEGAL DUMPING\n",
    "- GRAFFITI\n",
    "- RAT SIGHTING / RODENT\n",
    "\n",
    "**Street and infrastructure condition domain:**\n",
    "\n",
    "- STREET CONDITION\n",
    "- SIDEWALK CONDITION\n",
    "- POTHOLE\n",
    "- TRAFFIC SIGNAL CONDITION\n",
    "- STREET LIGHT CONDITION\n",
    "- BROKEN METER\n",
    "\n",
    "**Environmental stressors:**\n",
    "\n",
    "- SEWER\n",
    "- FLOODING\n",
    "- WATER SYSTEM\n",
    "- CONSTRUCTION NOISE\n",
    "- AIR QUALITY\n",
    "\n",
    "**Parks, trees, public space:**\n",
    "\n",
    "- TREE DAMAGE\n",
    "- TREE DEBRIS\n",
    "- DEAD TREE\n",
    "- PARK GENERAL\n",
    "- PLAYGROUND\n",
    "- PARK MAINTENANCE & CLEANLINESS\n",
    "\n",
    "**Neighborhood disorder:**\n",
    "\n",
    "- ABANDONED VEHICLE\n",
    "- DERELICT VEHICLE\n",
    "- BLOCKED DRIVEWAY\n",
    "- ILLEGAL PARKING\n",
    "\n",
    "Block groups data link: https://catalog.data.gov/dataset/tiger-line-shapefile-current-state-new-york-block-group\n",
    "\n",
    "311 data link: https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9/about_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf6dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import cenpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302962b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC block groups: 6807\n"
     ]
    }
   ],
   "source": [
    "# Load statewide 2020 block groups.\n",
    "bg_path = \"data/ny_block_groups_2020/ny_block_groups_2020.shp\"\n",
    "gdf_bg = gpd.read_file(bg_path)\n",
    "\n",
    "# Filter to NYC counties only.\n",
    "nyc_prefixes = (\"36005\", \"36047\", \"36061\", \"36081\", \"36085\")\n",
    "gdf_bg = gdf_bg[gdf_bg[\"GEOID\"].str.startswith(nyc_prefixes)].copy()\n",
    "\n",
    "print(\"NYC block groups:\", len(gdf_bg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "134c1060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2018…\n",
      "  Retrieved 50000 at offset 0\n",
      "  Retrieved 50000 at offset 50000\n",
      "  Retrieved 50000 at offset 100000\n",
      "  Retrieved 50000 at offset 150000\n",
      "  Retrieved 50000 at offset 200000\n",
      "  Retrieved 50000 at offset 250000\n",
      "  Retrieved 50000 at offset 300000\n",
      "  Retrieved 50000 at offset 350000\n",
      "  Retrieved 50000 at offset 400000\n",
      "  Retrieved 50000 at offset 450000\n",
      "  Retrieved 50000 at offset 500000\n",
      "  Retrieved 50000 at offset 550000\n",
      "  Retrieved 50000 at offset 600000\n",
      "  Retrieved 11902 at offset 650000\n",
      "Downloading 2019…\n",
      "  Retrieved 50000 at offset 0\n",
      "  Retrieved 50000 at offset 50000\n",
      "  Retrieved 50000 at offset 100000\n",
      "  Retrieved 50000 at offset 150000\n",
      "  Retrieved 50000 at offset 200000\n",
      "  Retrieved 50000 at offset 250000\n",
      "  Retrieved 50000 at offset 300000\n",
      "  Retrieved 50000 at offset 350000\n",
      "  Retrieved 50000 at offset 400000\n",
      "  Retrieved 50000 at offset 450000\n",
      "  Retrieved 50000 at offset 500000\n",
      "  Retrieved 50000 at offset 550000\n",
      "  Retrieved 46963 at offset 600000\n",
      "Downloading 2020…\n",
      "  Retrieved 50000 at offset 0\n",
      "  Retrieved 50000 at offset 50000\n",
      "  Retrieved 50000 at offset 100000\n",
      "  Retrieved 50000 at offset 150000\n",
      "  Retrieved 50000 at offset 200000\n",
      "  Retrieved 50000 at offset 250000\n",
      "  Retrieved 50000 at offset 300000\n",
      "  Retrieved 50000 at offset 350000\n",
      "  Retrieved 50000 at offset 400000\n",
      "  Retrieved 50000 at offset 450000\n",
      "  Retrieved 50000 at offset 500000\n",
      "  Retrieved 50000 at offset 550000\n",
      "  Retrieved 50000 at offset 600000\n",
      "  Retrieved 50000 at offset 650000\n",
      "  Retrieved 50000 at offset 700000\n",
      "  Retrieved 50000 at offset 750000\n",
      "  Retrieved 50000 at offset 800000\n",
      "  Retrieved 50000 at offset 850000\n",
      "  Retrieved 50000 at offset 900000\n",
      "  Retrieved 3653 at offset 950000\n",
      "Downloading 2021…\n",
      "  Retrieved 50000 at offset 0\n",
      "  Retrieved 50000 at offset 50000\n",
      "  Retrieved 50000 at offset 100000\n",
      "  Retrieved 50000 at offset 150000\n",
      "  Retrieved 50000 at offset 200000\n",
      "  Retrieved 50000 at offset 250000\n",
      "  Retrieved 50000 at offset 300000\n",
      "  Retrieved 50000 at offset 350000\n",
      "  Retrieved 50000 at offset 400000\n",
      "  Retrieved 50000 at offset 450000\n",
      "  Retrieved 50000 at offset 500000\n",
      "  Retrieved 50000 at offset 550000\n",
      "  Retrieved 50000 at offset 600000\n",
      "  Retrieved 50000 at offset 650000\n",
      "  Retrieved 50000 at offset 700000\n",
      "  Retrieved 50000 at offset 750000\n",
      "  Retrieved 50000 at offset 800000\n",
      "  Retrieved 16142 at offset 850000\n",
      "Downloading 2022…\n",
      "  Retrieved 50000 at offset 0\n",
      "  Retrieved 50000 at offset 50000\n",
      "  Retrieved 50000 at offset 100000\n",
      "  Retrieved 50000 at offset 150000\n",
      "  Retrieved 50000 at offset 200000\n",
      "  Retrieved 50000 at offset 250000\n",
      "  Retrieved 50000 at offset 300000\n",
      "  Retrieved 50000 at offset 350000\n",
      "  Retrieved 50000 at offset 400000\n",
      "  Retrieved 50000 at offset 450000\n",
      "  Retrieved 50000 at offset 500000\n",
      "  Retrieved 50000 at offset 550000\n",
      "  Retrieved 50000 at offset 600000\n",
      "  Retrieved 50000 at offset 650000\n",
      "  Retrieved 50000 at offset 700000\n",
      "  Retrieved 50000 at offset 750000\n",
      "  Retrieved 21516 at offset 800000\n",
      "Downloading 2023…\n",
      "  Retrieved 50000 at offset 0\n",
      "  Retrieved 50000 at offset 50000\n",
      "  Retrieved 50000 at offset 100000\n",
      "  Retrieved 50000 at offset 150000\n",
      "  Retrieved 50000 at offset 200000\n",
      "  Retrieved 50000 at offset 250000\n",
      "  Retrieved 50000 at offset 300000\n",
      "  Retrieved 50000 at offset 350000\n",
      "  Retrieved 50000 at offset 400000\n",
      "  Retrieved 50000 at offset 450000\n",
      "  Retrieved 50000 at offset 500000\n",
      "  Retrieved 50000 at offset 550000\n",
      "  Retrieved 50000 at offset 600000\n",
      "  Retrieved 50000 at offset 650000\n",
      "  Retrieved 50000 at offset 700000\n",
      "  Retrieved 50000 at offset 750000\n",
      "  Retrieved 26471 at offset 800000\n",
      "Downloading 2024…\n",
      "  Retrieved 50000 at offset 0\n",
      "  Retrieved 50000 at offset 50000\n",
      "  Retrieved 50000 at offset 100000\n",
      "  Retrieved 50000 at offset 150000\n",
      "  Retrieved 50000 at offset 200000\n",
      "  Retrieved 50000 at offset 250000\n",
      "  Retrieved 50000 at offset 300000\n",
      "  Retrieved 50000 at offset 350000\n",
      "  Retrieved 50000 at offset 400000\n",
      "  Retrieved 50000 at offset 450000\n",
      "  Retrieved 50000 at offset 500000\n",
      "  Retrieved 50000 at offset 550000\n",
      "  Retrieved 50000 at offset 600000\n",
      "  Retrieved 50000 at offset 650000\n",
      "  Retrieved 50000 at offset 700000\n",
      "  Retrieved 50000 at offset 750000\n",
      "  Retrieved 50000 at offset 800000\n",
      "  Retrieved 25876 at offset 850000\n",
      "Downloading 2025…\n",
      "  Retrieved 50000 at offset 0\n",
      "  Retrieved 50000 at offset 50000\n",
      "  Retrieved 50000 at offset 100000\n",
      "  Retrieved 50000 at offset 150000\n",
      "  Retrieved 50000 at offset 200000\n",
      "  Retrieved 50000 at offset 250000\n",
      "  Retrieved 50000 at offset 300000\n",
      "  Retrieved 50000 at offset 350000\n",
      "  Retrieved 50000 at offset 400000\n",
      "  Retrieved 50000 at offset 450000\n",
      "  Retrieved 50000 at offset 500000\n",
      "  Retrieved 50000 at offset 550000\n",
      "  Retrieved 50000 at offset 600000\n",
      "  Retrieved 50000 at offset 650000\n",
      "  Retrieved 50000 at offset 700000\n",
      "  Retrieved 50000 at offset 750000\n",
      "  Retrieved 6806 at offset 800000\n",
      "311 rows: 6459329\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://data.cityofnewyork.us/resource/erm2-nwe9.json\"\n",
    "app_token = \"vOli45DyYtVRbXMZ6YS2Amgjh\"\n",
    "page_size = 50000\n",
    "years = range(2018, 2026)\n",
    "\n",
    "select_cols = [\n",
    "    \"unique_key\", \"created_date\", \"complaint_type\",\n",
    "    \"descriptor\", \"latitude\", \"longitude\", \"borough\"\n",
    "]\n",
    "\n",
    "def download_311_summer_year(year):\n",
    "    print(f\"Downloading {year}…\")\n",
    "\n",
    "    start = f\"{year}-06-01T00:00:00\"\n",
    "    end   = f\"{year}-08-31T23:59:59\"\n",
    "\n",
    "    where = (\n",
    "        f\"created_date between '{start}' and '{end}' \"\n",
    "        \"AND latitude IS NOT NULL AND longitude IS NOT NULL\"\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        \"$select\": \",\".join(select_cols),\n",
    "        \"$where\": where,\n",
    "        \"$limit\": page_size,\n",
    "        \"$order\": \"created_date\"\n",
    "    }\n",
    "\n",
    "    headers = {\"X-App-Token\": app_token}\n",
    "\n",
    "    all_rows = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        params[\"$offset\"] = offset\n",
    "        r = requests.get(base_url, params=params, headers=headers)\n",
    "\n",
    "        if r.status_code != 200:\n",
    "            print(\"Error:\", r.status_code)\n",
    "            break\n",
    "\n",
    "        data = r.json()\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        all_rows.append(df)\n",
    "\n",
    "        print(f\"  Retrieved {len(df)} at offset {offset}\")\n",
    "        offset += page_size\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    if not all_rows:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    out = pd.concat(all_rows, ignore_index=True)\n",
    "    out[\"created_date\"] = pd.to_datetime(out[\"created_date\"])\n",
    "    out[\"year\"] = out[\"created_date\"].dt.year\n",
    "    out[\"date\"] = out[\"created_date\"].dt.date\n",
    "\n",
    "    out[\"latitude\"] = pd.to_numeric(out[\"latitude\"])\n",
    "    out[\"longitude\"] = pd.to_numeric(out[\"longitude\"])\n",
    "\n",
    "    return out\n",
    "\n",
    "# Download all years\n",
    "dfs = []\n",
    "for y in years:\n",
    "    df_y = download_311_summer_year(y)\n",
    "    if not df_y.empty:\n",
    "        dfs.append(df_y)\n",
    "\n",
    "df_311 = pd.concat(dfs, ignore_index=True)\n",
    "print(\"311 rows:\", len(df_311))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc382fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to GeoDataFrame\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(df_311.longitude, df_311.latitude)]\n",
    "gdf_311 = gpd.GeoDataFrame(df_311, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# Reproject to match BG CRS\n",
    "if gdf_311.crs != gdf_bg.crs:\n",
    "    gdf_311 = gdf_311.to_crs(gdf_bg.crs)\n",
    "\n",
    "# Spatial join\n",
    "gdf_joined = gpd.sjoin(\n",
    "    gdf_311,\n",
    "    gdf_bg[[\"GEOID\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"\n",
    ")\n",
    "\n",
    "gdf_joined = gdf_joined.dropna(subset=[\"GEOID\"]).copy()\n",
    "\n",
    "# Clean name\n",
    "gdf_joined.rename(columns={\"GEOID\": \"GEOID_BG\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e7eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel = (\n",
    "    gdf_joined\n",
    "    .groupby([\"GEOID_BG\", \"date\"], as_index=False)\n",
    "    .agg(\n",
    "        total_calls=(\"unique_key\", \"count\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd8ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "QOL_TYPES = [\n",
    "    \"HEAT\", \"HOT WATER\", \"WATER LEAK\", \"PLUMBING\", \"GAS\",\n",
    "    \"PAINT\", \"PLASTER\", \"ELECTRIC\", \"MOLD\", \"ELEVATOR\",\n",
    "    \"UNSANITARY\", \"DIRTY\", \"SANITATION\", \"HOUSING\", \"UNSAFE BUILDING\",\n",
    "    \"NOISE - RESIDENTIAL\", \"NOISE - PARK\", \"NOISE - STREET\",\n",
    "    \"RODENT\", \"AIR QUALITY\", \"GRAFFITI\", \"SEWER\", \"FLOODING\",\n",
    "    \"SIDEWALK\", \"POTHOLE\", \"TRAFFIC SIGNAL\", \"STREET LIGHT\",\n",
    "]\n",
    "\n",
    "gdf_joined[\"qol_flag\"] = gdf_joined[\"complaint_type\"].str.upper().isin(QOL_TYPES)\n",
    "\n",
    "qol_panel = (\n",
    "    gdf_joined\n",
    "    .groupby([\"GEOID_BG\", \"date\"])\n",
    "    .agg(qol_calls=(\"qol_flag\", \"sum\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_panel = df_panel.merge(qol_panel, on=[\"GEOID_BG\", \"date\"], how=\"left\")\n",
    "df_panel[\"qol_calls\"] = df_panel[\"qol_calls\"].fillna(0).astype(int)\n",
    "df_panel[\"qol_pct\"] = df_panel[\"qol_calls\"] / df_panel[\"total_calls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c979ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = pd.read_csv(\"data/nyc_heat_exposure_2018_2025.csv\")\n",
    "heat[\"DATE\"] = pd.to_datetime(heat[\"DATE\"])\n",
    "\n",
    "df_panel[\"date\"] = pd.to_datetime(df_panel[\"date\"])\n",
    "panel = df_panel.merge(heat, left_on=\"date\", right_on=\"DATE\", how=\"left\")\n",
    "panel = panel.drop(columns=[\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b0a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = cenpy.remote.APIConnection(\"ACSDT5Y2022\")\n",
    "\n",
    "acs_vars = [\n",
    "    \"NAME\",\n",
    "    \"B01003_001E\",  # total population\n",
    "    \"B19013_001E\",  # median HH income\n",
    "    \"B17001_001E\",  # poverty universe\n",
    "    \"B17001_002E\",  # poverty count\n",
    "    \"B25044_003E\"   # no-vehicle households\n",
    "]\n",
    "\n",
    "nyc_counties = [\"005\", \"047\", \"061\", \"081\", \"085\"]\n",
    "acs_dfs = []\n",
    "\n",
    "for county in nyc_counties:\n",
    "    df = api.query(\n",
    "        cols=acs_vars,\n",
    "        geo_unit=\"block group\",\n",
    "        geo_filter={\"state\": \"36\", \"county\": county}\n",
    "    )\n",
    "    acs_dfs.append(df)\n",
    "\n",
    "acs = pd.concat(acs_dfs, ignore_index=True)\n",
    "acs[\"GEOID_BG\"] = acs[\"state\"] + acs[\"county\"] + acs[\"tract\"] + acs[\"block group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5662e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_codes = [-666666666, -888888888, -222222222, -333333333]\n",
    "\n",
    "acs = acs.replace(bad_codes, np.nan)\n",
    "\n",
    "# Convert numerics\n",
    "for col in [\"B01003_001E\",\"B19013_001E\",\"B17001_001E\",\"B17001_002E\",\"B25044_003E\"]:\n",
    "    acs[col] = pd.to_numeric(acs[col], errors=\"coerce\")\n",
    "\n",
    "acs.rename(columns={\n",
    "    \"B01003_001E\":\"pop_total\",\n",
    "    \"B19013_001E\":\"medhhinc\",\n",
    "    \"B17001_001E\":\"poverty_universe\",\n",
    "    \"B17001_002E\":\"poverty_count\",\n",
    "    \"B25044_003E\":\"no_vehicle_hh\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b486298",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = panel.merge(acs, on=\"GEOID_BG\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "503b2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel[\"poverty_rate\"] = panel[\"poverty_count\"] / panel[\"poverty_universe\"]\n",
    "panel[\"poverty_rate\"] = panel.groupby(\"tract\")[\"poverty_rate\"].transform(lambda x: x.fillna(x.median()))\n",
    "panel[\"poverty_rate\"] = panel[\"poverty_rate\"].fillna(panel[\"poverty_rate\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b4cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel[\"poverty_rate\"] = panel[\"poverty_count\"] / panel[\"poverty_universe\"]\n",
    "panel[\"poverty_rate\"] = panel.groupby(\"tract\")[\"poverty_rate\"].transform(lambda x: x.fillna(x.median()))\n",
    "panel[\"poverty_rate\"] = panel[\"poverty_rate\"].fillna(panel[\"poverty_rate\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c958088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel[\"dow\"] = panel[\"date\"].dt.dayofweek\n",
    "panel[\"year\"] = panel[\"date\"].dt.year\n",
    "panel[\"log_total_calls\"] = np.log(panel[\"total_calls\"].replace(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09fa3d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# BUILD ALL REQUIRED MODEL VARIABLES BEFORE DROPPING NAs\n",
    "# ===========================================================\n",
    "\n",
    "# 1. Convert heat features\n",
    "panel[\"tmax_city_f\"] = panel[\"TMAX_CITY\"]\n",
    "panel[\"tmean_city_f\"] = panel[\"TMEAN_CITY\"]\n",
    "\n",
    "# 2. Safe poverty rate\n",
    "panel[\"poverty_rate\"] = (\n",
    "    panel[\"poverty_count\"] / panel[\"poverty_universe\"]\n",
    ").replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 3. Tract-level imputation\n",
    "panel[\"poverty_rate\"] = panel.groupby(\"tract\")[\"poverty_rate\"].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "# 4. Citywide fallback\n",
    "panel[\"poverty_rate\"] = panel[\"poverty_rate\"].fillna(panel[\"poverty_rate\"].median())\n",
    "\n",
    "# 5. Center SES variables\n",
    "panel[\"poverty_rate_c\"] = panel[\"poverty_rate\"] - panel[\"poverty_rate\"].mean()\n",
    "panel[\"medhhinc_c\"] = panel[\"medhhinc\"] - panel[\"medhhinc\"].mean()\n",
    "\n",
    "# 6. Interactions\n",
    "panel[\"extreme_x_poverty\"] = panel[\"EXTREME_HEAT\"] * panel[\"poverty_rate_c\"]\n",
    "panel[\"extreme_x_no_vehicle\"] = panel[\"EXTREME_HEAT\"] * (\n",
    "    panel[\"no_vehicle_hh\"] / panel[\"pop_total\"]\n",
    ")\n",
    "\n",
    "# 7. Time variables\n",
    "panel[\"dow\"] = panel[\"date\"].dt.dayofweek\n",
    "panel[\"year\"] = panel[\"date\"].dt.year\n",
    "\n",
    "# 8. Log offset\n",
    "panel[\"log_total_calls\"] = np.log(panel[\"total_calls\"].replace(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac423c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_clean = panel.dropna(subset=[\n",
    "    \"qol_calls\",\"total_calls\",\"poverty_rate_c\",\"medhhinc_c\",\n",
    "    \"EXTREME_HEAT\",\"tmax_city_f\",\"extreme_x_poverty\",\n",
    "    \"log_total_calls\"\n",
    "])\n",
    "\n",
    "panel_clean.to_csv(\n",
    "    \"data/model/nyc311_heat_acs_bg_2018_2025_final_regression_cleaned.csv\",\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
